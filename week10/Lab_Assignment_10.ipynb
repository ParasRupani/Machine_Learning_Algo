{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Assignment 10: <br>\n",
    "### Student Name: Paras Rupani\n",
    "### Student ID:   8961758"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This assignment targets to assure that the students understood basic IR concepts.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1: Implementing an IR System (10/16)**<br>\n",
    "\n",
    "Consider a collection of 1000 documents and a set of 10 queries. Implement an IR system based on the Vector Space Model (VSM) using TF-IDF weighting.<br>\n",
    "\n",
    "Dataset:<br>\n",
    "\n",
    "- 1000 documents (text content for each document)\n",
    "- 10 sample queries <br>\n",
    "IR System:<br>\n",
    "\n",
    "Implement TF-IDF calculation for document-term matrix construction. <br>\n",
    "Develop a cosine similarity-based retrieval system to rank documents for each query. <br>\n",
    "Rank the top 10 documents for each query using the IR system. <br>\n",
    "Evaluation: <br>\n",
    "\n",
    "Compute Precision at k (P@k) for k=5, k=6, and k=10 for each query.<br>\n",
    "Calculate Mean Average Precision (MAP) across all queries. <br>\n",
    "Calculate the Mean Reciprocal Rank (MRR) across all queries.(3) <br><br>\n",
    "**Part 2: Assessing Inter-Annotator Agreement (6/16)**<br>\n",
    "\n",
    "Given the relevance assessments by three different annotators for a set of documents:<br>\n",
    "\n",
    "Annotator 1,2 and 3 relevance assessments<br>\n",
    "\n",
    "You are expected to: <br>\n",
    "\n",
    "Compute pairwise Cohen's Kappa values for the annotators' relevance assessments.<br>\n",
    "Discuss the observed agreement levels among annotators.<br>\n",
    "Explain how to improve the kappa value if we are not satisfied with the kappa.<br>\n",
    "Hint: Check Kappa Measure Last Slide Week 11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------\n",
    "- Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    \"Machine learning is transforming various industries.\",\n",
    "    \"Natural language processing helps in text analysis.\",\n",
    "    \"AI algorithms can improve decision-making processes.\",\n",
    "    \"Data science involves extracting insights from data.\",\n",
    "    \"Robotics is a field combining hardware and software.\",\n",
    "    \"Deep learning models require large amounts of data.\",\n",
    "    \"Blockchain technology secures digital transactions.\",\n",
    "    \"Cloud computing offers scalable computing power.\",\n",
    "    \"Virtual reality provides immersive experiences.\",\n",
    "    \"Augmented reality enhances real-world environments.\",\n",
    "    \"Internet of Things connects devices for data exchange.\",\n",
    "    \"Biometric authentication ensures secure access.\",\n",
    "    \"Quantum computing promises faster computations.\",\n",
    "    \"Cybersecurity protects against digital threats.\",\n",
    "    \"Ethical considerations in AI development are crucial.\",\n",
    "    \"Healthcare benefits from AI-driven diagnostics.\",\n",
    "    \"E-commerce relies on personalized recommendation systems.\",\n",
    "    \"Autonomous vehicles revolutionize transportation.\",\n",
    "    \"Smart cities utilize IoT for efficient operations.\",\n",
    "    \"Social media analysis aids in understanding trends.\",\n",
    "    \"Predictive analytics anticipates future outcomes.\",\n",
    "    \"Remote work trends increase reliance on digital tools.\",\n",
    "    \"Energy efficiency through smart grids is vital.\",\n",
    "    \"Fintech innovations reshape financial services.\",\n",
    "    \"Data privacy concerns arise in the era of big data.\",\n",
    "    \"Artificial general intelligence remains a challenge.\",\n",
    "    \"Human-computer interaction shapes user experiences.\",\n",
    "    \"Big data analytics drives informed decision-making.\",\n",
    "    \"Climate change predictions benefit from AI models.\",\n",
    "    \"Bioinformatics applies computational techniques to biology.\",\n",
    "    \"Robotic process automation streamlines workflows.\",\n",
    "    \"Industry 4.0 integrates AI with manufacturing.\",\n",
    "    \"Sentiment analysis detects emotions in text data.\",\n",
    "    \"Reinforcement learning powers autonomous agents.\",\n",
    "    \"Data visualization simplifies complex information.\",\n",
    "    \"Edge computing reduces latency in data processing.\",\n",
    "    \"Smart farming optimizes agricultural practices.\",\n",
    "    \"AI in education enhances personalized learning.\",\n",
    "    \"Natural disaster predictions leverage machine learning.\",\n",
    "    \"Media recommendation systems personalize content.\",\n",
    "    \"Speech recognition enables hands-free interactions.\",\n",
    "    \"Genetic algorithms mimic natural selection.\",\n",
    "    \"Neural networks simulate the human brain.\",\n",
    "    \"Behavioral analytics uncovers patterns in behavior.\",\n",
    "    \"Spatial analysis benefits from geospatial data.\",\n",
    "    \"Explainable AI improves transparency in models.\",\n",
    "    \"AI ethics guide responsible technology development.\",\n",
    "    \"Prescriptive analytics offers actionable insights.\",\n",
    "    \"Supply chain optimization employs predictive models.\",\n",
    "    \"Emotion AI detects emotions in facial expressions.\",\n",
    "    \"Distributed ledger technology ensures secure transactions.\",\n",
    "    \"Biological data analysis aids in medical research.\",\n",
    "    \"Smart grid technology enhances energy distribution.\",\n",
    "    \"AI-powered chatbots automate customer support.\",\n",
    "    \"Machine translation breaks language barriers.\",\n",
    "    \"Personalized medicine tailors treatments to individuals.\",\n",
    "    \"Data-driven marketing optimizes customer engagement.\",\n",
    "    \"Smart home devices enhance living experiences.\",\n",
    "    \"Time series forecasting predicts future trends.\",\n",
    "    \"AI-driven creativity challenges human capabilities.\",\n",
    "    \"Intelligent document processing automates data extraction.\",\n",
    "    \"Graph analytics explores relationships in networks.\",\n",
    "    \"Adversarial attacks pose challenges to AI security.\",\n",
    "    \"Predictive maintenance minimizes equipment downtime.\",\n",
    "    \"Spatial reasoning enhances AI navigation systems.\",\n",
    "    \"Privacy-preserving techniques protect sensitive data.\",\n",
    "    \"Automated decision-making raises ethical concerns.\",\n",
    "    \"Behavioral biometrics verifies user identities.\",\n",
    "    \"Explainable recommendations increase user trust.\",\n",
    "    \"Quantum machine learning explores quantum states.\",\n",
    "    \"Internet censorship detection uses AI techniques.\",\n",
    "    \"Smart wearables monitor health and fitness.\",\n",
    "    \"Intelligent tutoring systems adapt to student needs.\",\n",
    "    \"Graph neural networks model complex relationships.\",\n",
    "    \"AI in sports analytics improves performance analysis.\",\n",
    "    \"Facial recognition technology raises privacy debates.\",\n",
    "    \"Digital twin technology replicates physical systems.\",\n",
    "    \"Emotion detection in video content aids analysis.\",\n",
    "    \"Neuromorphic computing mimics brain structure.\",\n",
    "    \"Robotic surgery enhances precision in operations.\",\n",
    "    \"AI-powered language translation assists global communication.\",\n",
    "    \"Automated content moderation filters online content.\",\n",
    "    \"Network anomaly detection identifies security threats.\",\n",
    "    \"Predictive policing uses data to prevent crime.\",\n",
    "    \"Quantum cryptography ensures secure communications.\",\n",
    "    \"AI-generated art challenges traditional creativity.\",\n",
    "    \"Ethical considerations in autonomous vehicles are debated.\",\n",
    "    \"Adaptive learning systems personalize educational content.\",\n",
    "    \"Biomedical image analysis aids in disease diagnosis.\",\n",
    "    \"Explainable computer vision interprets image features.\",\n",
    "    \"AI-driven personalization enhances user experiences.\",\n",
    "    \"Conversational AI improves human-like interactions.\",\n",
    "    \"Federated learning protects individual data privacy.\",\n",
    "    \"Human-centered AI design prioritizes user needs.\",\n",
    "    \"Quantum annealing solves optimization problems.\",\n",
    "    \"Behavior-based authentication enhances security.\",\n",
    "    \"AI in music composition transforms creative processes.\",\n",
    "    \"Semantic search improves information retrieval.\",\n",
    "    \"Recommender systems optimize user preferences.\",\n",
    "    \"Information Retrieval systems are outdated without neural networks\"\n",
    "]\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"What are the impacts of AI on healthcare?\",\n",
    "    \"How does machine learning improve financial services?\",\n",
    "    \"What is the role of AI in autonomous vehicles?\",\n",
    "    \"Explain the applications of natural language processing.\",\n",
    "    \"How does robotics benefit from AI integration?\",\n",
    "    \"What are the challenges in implementing AI in education?\",\n",
    "    \"How does data science contribute to climate change predictions?\",\n",
    "    \"What are the ethical considerations in AI development?\",\n",
    "    \"Explain the significance of AI in smart cities.\",\n",
    "    \"How does AI enhance cybersecurity measures?\"\n",
    "]\n",
    "print(len(queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "ground_truth =[[3, 74, 38, 92, 71, 72, 98, 48, 18, 100], \n",
    "                [12, 26, 52, 54, 21, 63, 64, 45, 14, 83],\n",
    "                [58, 77, 62, 31, 6, 61, 36, 96, 85, 18], \n",
    "                [99, 62, 98, 34, 63, 79, 43, 31, 3, 16],\n",
    "                [8, 88, 73, 82, 37, 25, 34, 87, 66, 58], \n",
    "                [90, 40, 84, 64, 34, 2, 73, 23, 59, 89],\n",
    "                [80, 10, 86, 21, 68, 37, 83, 57, 6, 98],\n",
    "                [22, 3, 2, 44, 56, 80, 50, 63, 87, 13],\n",
    "                [1, 18, 22, 44, 99, 72, 24, 95, 10, 87],\n",
    "                [31, 10, 56, 50, 75, 4, 18, 85, 84, 74]\n",
    "                           ]\n",
    "print(len(ground_truth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Implement your solution for part 1\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([15, 24, 14, 42, 16, 86, 21, 99,  5, 10]),\n",
       " array([23, 38,  0, 69,  2, 54, 37, 33, 92, 87]),\n",
       " array([17, 86, 24, 42, 33,  0, 37, 22,  5, 45]),\n",
       " array([ 1, 24, 42, 54, 41, 38, 60, 35, 80,  5]),\n",
       " array([28, 15,  4, 44,  3, 37, 45, 90, 64, 59]),\n",
       " array([37, 14, 86, 24, 59, 85, 45, 62, 74, 42]),\n",
       " array([28,  3, 83, 38, 29, 55, 62, 72, 24, 34]),\n",
       " array([14, 86, 46, 24, 42, 66, 37, 99, 45, 74]),\n",
       " array([24, 18, 42, 37,  5, 45, 10, 74, 36, 52]),\n",
       " array([13, 57, 37, 45, 90, 64, 59, 74, 31, 91])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a TfidfVectorizer instance for vectorizing queries and documents\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the documents into TF-IDF representation\n",
    "tfidf_documents = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Transform the queries into TF-IDF representation\n",
    "tfidf_queries = vectorizer.transform(queries)\n",
    "\n",
    "# Calculate cosine similarity between queries and documents\n",
    "cosine_sim = cosine_similarity(tfidf_queries, tfidf_documents)\n",
    "\n",
    "# Retrieve top 10 documents for each query based on cosine similarity\n",
    "lab_10_query = [np.argsort(cosine_similarity_row)[-10:][::-1] for cosine_similarity_row in cosine_sim]\n",
    "\n",
    "lab_10_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the impacts of AI on healthcare?\n",
      "Rank-1: Index:[15]\tHealthcare benefits from AI-driven diagnostics.\n",
      "Rank-2: Index:[24]\tData privacy concerns arise in the era of big data.\n",
      "Rank-3: Index:[14]\tEthical considerations in AI development are crucial.\n",
      "Rank-4: Index:[42]\tNeural networks simulate the human brain.\n",
      "Rank-5: Index:[16]\tE-commerce relies on personalized recommendation systems.\n",
      "Rank-6: Index:[86]\tEthical considerations in autonomous vehicles are debated.\n",
      "Rank-7: Index:[21]\tRemote work trends increase reliance on digital tools.\n",
      "Rank-8: Index:[99]\tInformation Retrieval systems are outdated without neural networks\n",
      "Rank-9: Index:[5]\tDeep learning models require large amounts of data.\n",
      "Rank-10: Index:[10]\tInternet of Things connects devices for data exchange.\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query: How does machine learning improve financial services?\n",
      "Rank-1: Index:[23]\tFintech innovations reshape financial services.\n",
      "Rank-2: Index:[38]\tNatural disaster predictions leverage machine learning.\n",
      "Rank-3: Index:[0]\tMachine learning is transforming various industries.\n",
      "Rank-4: Index:[69]\tQuantum machine learning explores quantum states.\n",
      "Rank-5: Index:[2]\tAI algorithms can improve decision-making processes.\n",
      "Rank-6: Index:[54]\tMachine translation breaks language barriers.\n",
      "Rank-7: Index:[37]\tAI in education enhances personalized learning.\n",
      "Rank-8: Index:[33]\tReinforcement learning powers autonomous agents.\n",
      "Rank-9: Index:[92]\tFederated learning protects individual data privacy.\n",
      "Rank-10: Index:[87]\tAdaptive learning systems personalize educational content.\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query: What is the role of AI in autonomous vehicles?\n",
      "Rank-1: Index:[17]\tAutonomous vehicles revolutionize transportation.\n",
      "Rank-2: Index:[86]\tEthical considerations in autonomous vehicles are debated.\n",
      "Rank-3: Index:[24]\tData privacy concerns arise in the era of big data.\n",
      "Rank-4: Index:[42]\tNeural networks simulate the human brain.\n",
      "Rank-5: Index:[33]\tReinforcement learning powers autonomous agents.\n",
      "Rank-6: Index:[0]\tMachine learning is transforming various industries.\n",
      "Rank-7: Index:[37]\tAI in education enhances personalized learning.\n",
      "Rank-8: Index:[22]\tEnergy efficiency through smart grids is vital.\n",
      "Rank-9: Index:[5]\tDeep learning models require large amounts of data.\n",
      "Rank-10: Index:[45]\tExplainable AI improves transparency in models.\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query: Explain the applications of natural language processing.\n",
      "Rank-1: Index:[1]\tNatural language processing helps in text analysis.\n",
      "Rank-2: Index:[24]\tData privacy concerns arise in the era of big data.\n",
      "Rank-3: Index:[42]\tNeural networks simulate the human brain.\n",
      "Rank-4: Index:[54]\tMachine translation breaks language barriers.\n",
      "Rank-5: Index:[41]\tGenetic algorithms mimic natural selection.\n",
      "Rank-6: Index:[38]\tNatural disaster predictions leverage machine learning.\n",
      "Rank-7: Index:[60]\tIntelligent document processing automates data extraction.\n",
      "Rank-8: Index:[35]\tEdge computing reduces latency in data processing.\n",
      "Rank-9: Index:[80]\tAI-powered language translation assists global communication.\n",
      "Rank-10: Index:[5]\tDeep learning models require large amounts of data.\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query: How does robotics benefit from AI integration?\n",
      "Rank-1: Index:[28]\tClimate change predictions benefit from AI models.\n",
      "Rank-2: Index:[15]\tHealthcare benefits from AI-driven diagnostics.\n",
      "Rank-3: Index:[4]\tRobotics is a field combining hardware and software.\n",
      "Rank-4: Index:[44]\tSpatial analysis benefits from geospatial data.\n",
      "Rank-5: Index:[3]\tData science involves extracting insights from data.\n",
      "Rank-6: Index:[37]\tAI in education enhances personalized learning.\n",
      "Rank-7: Index:[45]\tExplainable AI improves transparency in models.\n",
      "Rank-8: Index:[90]\tAI-driven personalization enhances user experiences.\n",
      "Rank-9: Index:[64]\tSpatial reasoning enhances AI navigation systems.\n",
      "Rank-10: Index:[59]\tAI-driven creativity challenges human capabilities.\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query: What are the challenges in implementing AI in education?\n",
      "Rank-1: Index:[37]\tAI in education enhances personalized learning.\n",
      "Rank-2: Index:[14]\tEthical considerations in AI development are crucial.\n",
      "Rank-3: Index:[86]\tEthical considerations in autonomous vehicles are debated.\n",
      "Rank-4: Index:[24]\tData privacy concerns arise in the era of big data.\n",
      "Rank-5: Index:[59]\tAI-driven creativity challenges human capabilities.\n",
      "Rank-6: Index:[85]\tAI-generated art challenges traditional creativity.\n",
      "Rank-7: Index:[45]\tExplainable AI improves transparency in models.\n",
      "Rank-8: Index:[62]\tAdversarial attacks pose challenges to AI security.\n",
      "Rank-9: Index:[74]\tAI in sports analytics improves performance analysis.\n",
      "Rank-10: Index:[42]\tNeural networks simulate the human brain.\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query: How does data science contribute to climate change predictions?\n",
      "Rank-1: Index:[28]\tClimate change predictions benefit from AI models.\n",
      "Rank-2: Index:[3]\tData science involves extracting insights from data.\n",
      "Rank-3: Index:[83]\tPredictive policing uses data to prevent crime.\n",
      "Rank-4: Index:[38]\tNatural disaster predictions leverage machine learning.\n",
      "Rank-5: Index:[29]\tBioinformatics applies computational techniques to biology.\n",
      "Rank-6: Index:[55]\tPersonalized medicine tailors treatments to individuals.\n",
      "Rank-7: Index:[62]\tAdversarial attacks pose challenges to AI security.\n",
      "Rank-8: Index:[72]\tIntelligent tutoring systems adapt to student needs.\n",
      "Rank-9: Index:[24]\tData privacy concerns arise in the era of big data.\n",
      "Rank-10: Index:[34]\tData visualization simplifies complex information.\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query: What are the ethical considerations in AI development?\n",
      "Rank-1: Index:[14]\tEthical considerations in AI development are crucial.\n",
      "Rank-2: Index:[86]\tEthical considerations in autonomous vehicles are debated.\n",
      "Rank-3: Index:[46]\tAI ethics guide responsible technology development.\n",
      "Rank-4: Index:[24]\tData privacy concerns arise in the era of big data.\n",
      "Rank-5: Index:[42]\tNeural networks simulate the human brain.\n",
      "Rank-6: Index:[66]\tAutomated decision-making raises ethical concerns.\n",
      "Rank-7: Index:[37]\tAI in education enhances personalized learning.\n",
      "Rank-8: Index:[99]\tInformation Retrieval systems are outdated without neural networks\n",
      "Rank-9: Index:[45]\tExplainable AI improves transparency in models.\n",
      "Rank-10: Index:[74]\tAI in sports analytics improves performance analysis.\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query: Explain the significance of AI in smart cities.\n",
      "Rank-1: Index:[24]\tData privacy concerns arise in the era of big data.\n",
      "Rank-2: Index:[18]\tSmart cities utilize IoT for efficient operations.\n",
      "Rank-3: Index:[42]\tNeural networks simulate the human brain.\n",
      "Rank-4: Index:[37]\tAI in education enhances personalized learning.\n",
      "Rank-5: Index:[5]\tDeep learning models require large amounts of data.\n",
      "Rank-6: Index:[45]\tExplainable AI improves transparency in models.\n",
      "Rank-7: Index:[10]\tInternet of Things connects devices for data exchange.\n",
      "Rank-8: Index:[74]\tAI in sports analytics improves performance analysis.\n",
      "Rank-9: Index:[36]\tSmart farming optimizes agricultural practices.\n",
      "Rank-10: Index:[52]\tSmart grid technology enhances energy distribution.\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "Query: How does AI enhance cybersecurity measures?\n",
      "Rank-1: Index:[13]\tCybersecurity protects against digital threats.\n",
      "Rank-2: Index:[57]\tSmart home devices enhance living experiences.\n",
      "Rank-3: Index:[37]\tAI in education enhances personalized learning.\n",
      "Rank-4: Index:[45]\tExplainable AI improves transparency in models.\n",
      "Rank-5: Index:[90]\tAI-driven personalization enhances user experiences.\n",
      "Rank-6: Index:[64]\tSpatial reasoning enhances AI navigation systems.\n",
      "Rank-7: Index:[59]\tAI-driven creativity challenges human capabilities.\n",
      "Rank-8: Index:[74]\tAI in sports analytics improves performance analysis.\n",
      "Rank-9: Index:[31]\tIndustry 4.0 integrates AI with manufacturing.\n",
      "Rank-10: Index:[91]\tConversational AI improves human-like interactions.\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over each query and its index using enumerate\n",
    "for i, doc_queries in enumerate(queries):\n",
    "    print(\"Query:\", doc_queries)    \n",
    "    for rank, doc_index in enumerate(lab_10_query[i]):    \n",
    "        print(f'Rank-{rank+1}: Index:{[doc_index]}\\t{documents[doc_index]}')\n",
    "    \n",
    "    print(\"\\n------------------------------------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, creating a function to calculate Precision at k\n",
    "def precision_at_k(document_retrieved, ground_truth_docs, k):\n",
    "    \"\"\"\n",
    "    Calculate Precision at k for retrieved documents.\n",
    "\n",
    "    Args:\n",
    "        document_retrieved (list): List of retrieved document IDs.\n",
    "        ground_truth_docs (set): Set of ground truth document IDs.\n",
    "        k (int): Value of k for precision@k.\n",
    "\n",
    "    Returns:\n",
    "        float: Precision at k.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert ground_truth_docs to a set for faster intersection operation\n",
    "    document_relevant = set(ground_truth_docs)\n",
    "    documents_retrieved_at_k = set(document_retrieved[:k]) # top k retrieved documents\n",
    "    true_positives = len(document_relevant.intersection(documents_retrieved_at_k)) # number of true positives\n",
    "    \n",
    "    print(f\"Retrieved Document at {k} \\n {documents_retrieved_at_k}\")\n",
    "\n",
    "    return true_positives / k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Document at 5 \n",
      " {42, 14, 15, 16, 24}\n",
      "Retrieved Document at 6 \n",
      " {42, 14, 15, 16, 86, 24}\n",
      "Retrieved Document at 10 \n",
      " {99, 5, 42, 10, 14, 15, 16, 21, 86, 24}\n",
      "Retrieved Document at 5 \n",
      " {0, 2, 69, 38, 23}\n",
      "Retrieved Document at 6 \n",
      " {0, 2, 69, 38, 54, 23}\n",
      "Retrieved Document at 10 \n",
      " {0, 33, 2, 69, 38, 37, 54, 23, 87, 92}\n",
      "Retrieved Document at 5 \n",
      " {33, 42, 17, 86, 24}\n",
      "Retrieved Document at 6 \n",
      " {0, 33, 42, 17, 86, 24}\n",
      "Retrieved Document at 10 \n",
      " {0, 33, 37, 5, 42, 45, 17, 86, 22, 24}\n",
      "Retrieved Document at 5 \n",
      " {1, 41, 42, 54, 24}\n",
      "Retrieved Document at 6 \n",
      " {1, 38, 41, 42, 54, 24}\n",
      "Retrieved Document at 10 \n",
      " {1, 35, 5, 38, 41, 42, 80, 54, 24, 60}\n",
      "Retrieved Document at 5 \n",
      " {3, 4, 44, 15, 28}\n",
      "Retrieved Document at 6 \n",
      " {3, 4, 37, 44, 15, 28}\n",
      "Retrieved Document at 10 \n",
      " {64, 3, 4, 37, 44, 45, 15, 90, 59, 28}\n",
      "Retrieved Document at 5 \n",
      " {37, 14, 86, 24, 59}\n",
      "Retrieved Document at 6 \n",
      " {37, 14, 85, 86, 24, 59}\n",
      "Retrieved Document at 10 \n",
      " {37, 74, 42, 45, 14, 85, 86, 24, 59, 62}\n",
      "Retrieved Document at 5 \n",
      " {3, 38, 83, 28, 29}\n",
      "Retrieved Document at 6 \n",
      " {3, 38, 83, 55, 28, 29}\n",
      "Retrieved Document at 10 \n",
      " {34, 3, 38, 72, 83, 55, 24, 28, 29, 62}\n",
      "Retrieved Document at 5 \n",
      " {42, 46, 14, 86, 24}\n",
      "Retrieved Document at 6 \n",
      " {66, 42, 46, 14, 86, 24}\n",
      "Retrieved Document at 10 \n",
      " {66, 99, 37, 42, 74, 45, 46, 14, 86, 24}\n",
      "Retrieved Document at 5 \n",
      " {5, 37, 42, 18, 24}\n",
      "Retrieved Document at 6 \n",
      " {5, 37, 42, 45, 18, 24}\n",
      "Retrieved Document at 10 \n",
      " {36, 5, 37, 42, 10, 74, 45, 18, 52, 24}\n",
      "Retrieved Document at 5 \n",
      " {37, 45, 13, 57, 90}\n",
      "Retrieved Document at 6 \n",
      " {64, 37, 45, 13, 57, 90}\n",
      "Retrieved Document at 10 \n",
      " {64, 37, 74, 91, 45, 13, 57, 90, 59, 31}\n"
     ]
    }
   ],
   "source": [
    "# Calculating precision at k and mapping\n",
    "precisions = {k: [] for k in [5, 6, 10]}\n",
    "\n",
    "# Processing each query and its retrieved documents\n",
    "for query, document_retrieved in enumerate(lab_10_query):\n",
    "    ground_truth_docs = ground_truth[query] # Retriving Ground Truth\n",
    "    for k in precisions:\n",
    "        # Append precision at k for the current query to the list\n",
    "        precisions[k].append(precision_at_k(document_retrieved, ground_truth_docs, k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, creating another function to calculate MRR\n",
    "def MRR(document_retrieved_list, ground_truth_list):\n",
    "    \"\"\"\n",
    "    Calculate Mean Reciprocal Rank (MRR) for a list of queries.\n",
    "\n",
    "    Args:\n",
    "        document_retrieved_list (list): List of lists, each containing retrieved document IDs for a query.\n",
    "        ground_truth_list (list): List of sets, each containing ground truth document IDs for a query.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean Reciprocal Rank (MRR).\n",
    "    \"\"\"\n",
    "\n",
    "    mrr = 0\n",
    "\n",
    "    # Interating Over Retrieved Documents\n",
    "    for document_retrieved, ground_truth_docs in zip(document_retrieved_list, ground_truth_list): \n",
    "        \n",
    "        # Finding Rank of First Relevant Document\n",
    "        for rank, document_id in enumerate(document_retrieved, start=1): \n",
    "            if document_id in ground_truth_docs: # Checking Relevancy\n",
    "                mrr += 1 / rank\n",
    "                break\n",
    "    # Calculating Mean Reciprocal Rank\n",
    "    return mrr / len(document_retrieved_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision at k=5: [0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.2, 0.0, 0.4, 0.0]\n",
      "Mean Average Precision (MAP) of k=5: 0.08 \n",
      "\n",
      "Precision at k=6: [0.0, 0.17, 0.0, 0.0, 0.17, 0.17, 0.17, 0.0, 0.33, 0.0]\n",
      "Mean Average Precision (MAP) of k=6: 0.1 \n",
      "\n",
      "Precision at k=10: [0.0, 0.1, 0.0, 0.0, 0.1, 0.1, 0.1, 0.0, 0.3, 0.2]\n",
      "Mean Average Precision (MAP) of k=10: 0.09 \n",
      "\n",
      "Mean Average Precision (MAP): 0.09\n",
      "Mean Reciprocal Rank (MRR): 0.2\n"
     ]
    }
   ],
   "source": [
    "# Calculating Mean Reciprocal Rank using the function\n",
    "mrr_score = MRR(lab_10_query, ground_truth)\n",
    "\n",
    "\n",
    "for k, values in precisions.items():\n",
    "    # Round each value in the list to 2 decimal places\n",
    "    k_values = [round(value, 2) for value in values]\n",
    "    print(f\"Precision at k={k}: {k_values}\")\n",
    "    \n",
    "    # MAP score for the current k\n",
    "    map_score_k = sum(values) / len(values)\n",
    "    # MAP score for the current k\n",
    "    print(f\"Mean Average Precision (MAP) of k={k}: {map_score_k} \\n\")\n",
    "    \n",
    "    # Overall Mean MAP score \n",
    "    map_score = np.mean(map_score_k)\n",
    "\n",
    "# Overall MAP score\n",
    "print(\"Mean Average Precision (MAP):\", map_score)\n",
    "\n",
    "# MRR Score\n",
    "print(\"Mean Reciprocal Rank (MRR):\", round(mrr_score, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------\n",
    "**Part 2: Assessing Inter-Annotator Agreement (6/16)**<br>\n",
    "\n",
    "Given the relevance assessments by three different annotators for a set of documents:<br>\n",
    "\n",
    "Annotator 1,2 and 3 relevance assessments<br>\n",
    "\n",
    "You are expected to: <br>\n",
    "\n",
    "Compute pairwise Cohen's Kappa values for the annotators' relevance assessments.<br>\n",
    "Discuss the observed agreement levels among annotators.<br>\n",
    "Explain how to improve the kappa value if we are not satisfied with the kappa.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is not relevant, 1 is relevant\n",
    "annotator1_relevance = [1, 0, 1, 0, 1, 1, 0, 0, 1, 0]  \n",
    "annotator2_relevance = [1, 1, 1, 0, 1, 0, 0, 1, 1, 1]  \n",
    "annotator3_relevance = [1, 0, 0, 0, 1, 0, 0, 1, 1, 0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa between Pairs 1 and 2: 0.2\n",
      "Kappa between Pairs 2 and 3: 0.44\n",
      "Kappa between Pairs 1 and 3: 0.4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annotator Pairs</th>\n",
       "      <th>Cohen's Kappa Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 and 2</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 and 3</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 and 3</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Annotator Pairs  Cohen's Kappa Score\n",
       "0         1 and 2                 0.20\n",
       "1         2 and 3                 0.44\n",
       "2         1 and 3                 0.40"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO: Implement your solution for part 2\n",
    "\n",
    "# Calculating cohen_kappa_score() for annotator 1,2 and 3\n",
    "kappa_1_2 = cohen_kappa_score(annotator1_relevance, annotator2_relevance)\n",
    "kappa_2_3 = cohen_kappa_score(annotator2_relevance, annotator3_relevance)\n",
    "kappa_1_3 = cohen_kappa_score(annotator1_relevance, annotator3_relevance)\n",
    "\n",
    "# Dictionary holding the data\n",
    "data = {\n",
    "    'Annotator Pairs': ['1 and 2', '2 and 3', '1 and 3'],\n",
    "    'Cohen\\'s Kappa Score': [round(kappa_1_2, 2), round(kappa_2_3, 2), round(kappa_1_3, 2)]\n",
    "}\n",
    "\n",
    "for pair, kappa_score in zip(data['Annotator Pairs'], data['Cohen\\'s Kappa Score']):\n",
    "    print(f\"Kappa between Pairs {pair}: {kappa_score}\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
